{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7ffd8cb-6c01-4e75-a739-1479c5f8a1f3",
   "metadata": {},
   "source": [
    "# ðŸš¨ AML Network Analysis with Graph + Machine Learning\n",
    "\n",
    "This project analyzes a banking transaction dataset to detect suspicious accounts using:\n",
    "\n",
    "- **NetworkX** for transaction graph modeling  \n",
    "- **Isolation Forest (Scikit-learn)** for anomaly detection  \n",
    "- **PostgreSQL + SQLAlchemy** for data integration\n",
    "\n",
    "## Output\n",
    "- `all_accounts.csv`: all accounts with money sent/received and connections\n",
    "- `suspicious_accounts.csv`: flagged suspicious accounts\n",
    "\n",
    "> Replace credentials like username, password, and port before running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "06574cb5-b0fb-4e71-b80f-cae37cc1bf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Analysis\n",
      " Dataset: 1048575 transactions, 1497908 accounts\n",
      "Building transaction graph\n",
      "Calculating features\n",
      "Finding suspicious accounts\n",
      "\n",
      " Found 149108 suspicious accounts:\n",
      "        account_id  money_sent  money_received  suspicion_score\n",
      "721      C11003494         0.0     24351218.72        -0.367223\n",
      "367    C1789550256         0.0     28376404.29        -0.367223\n",
      "179    C1286084959         0.0     33821294.10        -0.367223\n",
      "746    C1816757085         0.0     25861438.32        -0.367223\n",
      "16879   C423580937         0.0     24536518.17        -0.367223\n",
      "341    C1504109395         0.0     22572409.85        -0.367223\n",
      "1152    C667346055         0.0     25382158.07        -0.367223\n",
      "204    C1870252780         0.0     20814145.76        -0.367223\n",
      "206      C97730845         0.0     41811504.75        -0.367223\n",
      "1139    C306206744         0.0     24331178.88        -0.367223\n",
      "\n",
      " Analysis complete!\n",
      " Files saved: suspicious_accounts.csv, all_accounts.csv\n",
      " Most suspicious account: C11003494\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sqlalchemy import create_engine\n",
    "db_user = 'postgres'      \n",
    "db_password = '1234'   \n",
    "db_host = 'localhost'\n",
    "db_port = '5433'\n",
    "db_name = 'kunwar_retail_db'\n",
    "engine = create_engine(f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "#Load data from PostgreSQL\n",
    "banking_data = pd.read_sql(\"SELECT * FROM banking_data\", engine)\n",
    "\n",
    "print('Starting Analysis')\n",
    "print(f\" Dataset: {len(banking_data)} transactions, \"\n",
    "      f\"{len(set(banking_data['nameorig'].tolist() + banking_data['namedest'].tolist()))} accounts\")\n",
    "\n",
    "#Build transaction network\n",
    "print('Building transaction graph')\n",
    "G = nx.DiGraph()\n",
    "for _, row in banking_data.iterrows():\n",
    "    G.add_edge(row['nameorig'], row['namedest'], weight=row['amount'])\n",
    "\n",
    "#Feature engineering\n",
    "print('Calculating features')\n",
    "features = []\n",
    "for account in G.nodes():\n",
    "    money_sent = sum(G[account][neighbor]['weight'] for neighbor in G.successors(account))\n",
    "    money_received = sum(G[neighbor][account]['weight'] for neighbor in G.predecessors(account))\n",
    "    connections = G.degree(account)\n",
    "\n",
    "    features.append({\n",
    "        'account_id': account,\n",
    "        'money_sent': money_sent,\n",
    "        'money_received': money_received,\n",
    "        'connections': connections\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(features)\n",
    "\n",
    "#inactive accounts\n",
    "df = df[(df['money_sent'] > 0) | (df['money_received'] > 0)]\n",
    "\n",
    "#Isolation Forest(Anomlly detection)\n",
    "print('Finding suspicious accounts')\n",
    "X = df[['money_sent', 'money_received', 'connections']]\n",
    "model = IsolationForest(contamination=0.1, random_state=42)\n",
    "df['is_suspicious'] = model.fit_predict(X) == -1\n",
    "df['suspicion_score'] = model.decision_function(X)\n",
    "\n",
    "\n",
    "suspicious = df[df['is_suspicious']].sort_values('suspicion_score')\n",
    "\n",
    "print(f\"\\n Found {len(suspicious)} suspicious accounts:\")\n",
    "print(suspicious[['account_id', 'money_sent', 'money_received', 'suspicion_score']].head(10))\n",
    "\n",
    "suspicious.to_csv('suspicious_accounts.csv', index=False)\n",
    "df.to_csv('all_accounts.csv', index=False)\n",
    "\n",
    "print(f\"\\n Analysis complete!\")\n",
    "print(f\" Files saved: suspicious_accounts.csv, all_accounts.csv\")\n",
    "print(f\" Most suspicious account: {suspicious.iloc[0]['account_id'] if len(suspicious) > 0 else 'None'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9997db8a-9e28-418e-b295-dbf459bf5763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning data...\n",
      "ðŸ“Š Cleaned shape: (1048575, 11)\n",
      "               step        amount    oldbalorig    newbalorig    oldbaldest  \\\n",
      "count  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06  1.048575e+06   \n",
      "mean   2.696617e+01  1.586670e+05  8.740095e+05  8.938089e+05  9.781600e+05   \n",
      "std    1.562325e+01  2.649409e+05  2.971751e+06  3.008271e+06  2.296780e+06   \n",
      "min    1.000000e+00  1.000000e-01  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    1.500000e+01  1.214907e+04  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "50%    2.000000e+01  7.634333e+04  1.600200e+04  0.000000e+00  1.263772e+05   \n",
      "75%    3.900000e+01  2.137619e+05  1.366420e+05  1.746000e+05  9.159235e+05   \n",
      "max    9.500000e+01  1.000000e+07  3.890000e+07  3.890000e+07  4.210000e+07   \n",
      "\n",
      "         newbaldest       isfraud  isflaggedfraud  \n",
      "count  1.048575e+06  1.048575e+06       1048575.0  \n",
      "mean   1.114198e+06  1.089097e-03             0.0  \n",
      "std    2.416593e+06  3.298351e-02             0.0  \n",
      "min    0.000000e+00  0.000000e+00             0.0  \n",
      "25%    0.000000e+00  0.000000e+00             0.0  \n",
      "50%    2.182604e+05  0.000000e+00             0.0  \n",
      "75%    1.149808e+06  0.000000e+00             0.0  \n",
      "max    4.220000e+07  1.000000e+00             0.0  \n",
      "âœ… Saved: data/cleaned_banking_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Connect to DB\n",
    "db_user = 'postgres'\n",
    "db_password = '1234'\n",
    "db_host = 'localhost'\n",
    "db_port = '5433'\n",
    "db_name = 'kunwar_retail_db'\n",
    "engine = create_engine(f'postgresql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}')\n",
    "\n",
    "# Load data\n",
    "df = pd.read_sql(\"SELECT * FROM banking_data\", engine)\n",
    "\n",
    "#  Clean\n",
    "print(\"Cleaning data...\")\n",
    "df = df.drop_duplicates()\n",
    "df = df[df['amount'] > 0]\n",
    "df = df.dropna()\n",
    "\n",
    "# Optional sanity check\n",
    "print(\" Cleaned shape:\", df.shape)\n",
    "print(df.describe())\n",
    "import os\n",
    "\n",
    "# Create 'data' folder if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Then save file\n",
    "df.to_csv('data/cleaned_banking_data.csv', index=False)\n",
    "\n",
    "# Step 4: Save cleaned file\n",
    "df.to_csv('data/cleaned_banking_data.csv', index=False)\n",
    "print(\" Saved: data/cleaned_banking_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6239584c-cdcc-4f2a-94a0-e2f64903e932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cleaned data: 1048575 transactions\n",
      "Building transaction network...\n",
      "Extracting graph features\n",
      " Detecting suspicious accounts\n",
      "\n",
      " Top 10 Suspicious Accounts:\n",
      "        account_id  money_sent  money_received  connections  suspicion_score\n",
      "721      C11003494         0.0     24351218.72           69        -0.367223\n",
      "367    C1789550256         0.0     28376404.29           73        -0.367223\n",
      "179    C1286084959         0.0     33821294.10           96        -0.367223\n",
      "746    C1816757085         0.0     25861438.32           69        -0.367223\n",
      "16879   C423580937         0.0     24536518.17           59        -0.367223\n",
      "341    C1504109395         0.0     22572409.85           69        -0.367223\n",
      "1152    C667346055         0.0     25382158.07           73        -0.367223\n",
      "204    C1870252780         0.0     20814145.76           60        -0.367223\n",
      "206      C97730845         0.0     41811504.75           79        -0.367223\n",
      "1139    C306206744         0.0     24331178.88           79        -0.367223\n",
      "saved to suspicious_accounts.csv\n",
      "Most suspicious account: C11003494\n"
     ]
    }
   ],
   "source": [
    "# run_model.py\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "\n",
    "# Step 1: Load Cleaned Data\n",
    "df = pd.read_csv('data/cleaned_banking_data.csv')\n",
    "print(f\"Loaded cleaned data: {df.shape[0]} transactions\")\n",
    "\n",
    "# Step 2: Build Transaction Graph\n",
    "print(\"Building transaction network...\")\n",
    "G = nx.DiGraph()\n",
    "for _, row in df.iterrows():\n",
    "    G.add_edge(row['nameorig'], row['namedest'], weight=row['amount'])\n",
    "\n",
    "# Step 3: Feature Engineering\n",
    "print(\"Extracting graph features\")\n",
    "features = []\n",
    "for account in G.nodes():\n",
    "    money_sent = sum(G[account][nbr]['weight'] for nbr in G.successors(account))\n",
    "    money_received = sum(G[nbr][account]['weight'] for nbr in G.predecessors(account))\n",
    "    connections = G.degree(account)\n",
    "\n",
    "    features.append({\n",
    "        'account_id': account,\n",
    "        'money_sent': money_sent,\n",
    "        'money_received': money_received,\n",
    "        'connections': connections\n",
    "    })\n",
    "\n",
    "account_df = pd.DataFrame(features)\n",
    "account_df = account_df[(account_df['money_sent'] > 0) | (account_df['money_received'] > 0)]\n",
    "\n",
    "# Step 4: Z-Score Normalization\n",
    "X = account_df[['money_sent', 'money_received', 'connections']]\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 5: Isolation Forest\n",
    "print(\" Detecting suspicious accounts\")\n",
    "model = IsolationForest(contamination=0.1, random_state=42)\n",
    "account_df['is_suspicious'] = model.fit_predict(X_scaled) == -1\n",
    "account_df['suspicion_score'] = model.decision_function(X_scaled)\n",
    "\n",
    "top_suspicious = account_df[account_df['is_suspicious']].sort_values('suspicion_score')\n",
    "print(f\"\\n Top 10 Suspicious Accounts:\")\n",
    "print(top_suspicious[['account_id', 'money_sent', 'money_received', 'connections', 'suspicion_score']].head(10))\n",
    "\n",
    "# Step 6: Export Results\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "account_df.to_csv('output/all_accounts.csv', index=False)\n",
    "account_df[account_df['is_suspicious']].to_csv('output/suspicious_accounts.csv', index=False)\n",
    "\n",
    "print(f\"saved to suspicious_accounts.csv\")\n",
    "print(f\"Most suspicious account: {account_df[account_df['is_suspicious']].sort_values('suspicion_score').iloc[0]['account_id']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b1b296-6030-4a6f-a7d2-b1deb6de6337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved top 20 suspicious accounts to 'output/top_suspicious_accounts.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your suspicious accounts data\n",
    "df = pd.read_csv('output/suspicious_accounts.csv')\n",
    "\n",
    "# Sort by suspicion score (lower = more suspicious)\n",
    "df_sorted = df.sort_values(by='suspicion_score', ascending=True)\n",
    "\n",
    "# Get top N suspicious accounts (e.g. 20)\n",
    "top_n = 20\n",
    "top_suspicious = df_sorted.head(top_n)\n",
    "\n",
    "# Save to new CSV\n",
    "top_suspicious.to_csv('output/top_20_suspicious_accounts.csv', index=False)\n",
    "\n",
    "print(f\"âœ… Saved top {top_n} suspicious accounts to 'output/top_suspicious_accounts.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831c1a43-8c00-4b0d-af7b-862b2ecd804d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce2482-4f9e-4561-8226-055386613cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1dd983-4db1-4d70-b939-a5ad71ea2343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
